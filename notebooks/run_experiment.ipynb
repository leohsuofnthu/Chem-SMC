{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified Constraint-Based Molecule Generation\n",
    "## GPT2-Zinc Baseline + SmileyLlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "environment"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analyze Training Data and Compute Constraint Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analyze_train_data import main as analyze_train_data\n",
    "\n",
    "# Analyze training data and compute constraint ranges (loose/tight/ultra_tight)\n",
    "analyze_train_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# View computed constraint ranges\n",
    "with open(\"data/train_property_ranges.json\", \"r\", encoding=\"utf-8\") as fp:\n",
    "    ranges = json.load(fp)\n",
    "\n",
    "# Show constraint levels for Combined dataset\n",
    "print(\"Constraint Levels (Combined dataset):\")\n",
    "for level in [\"loose\", \"tight\", \"ultra_tight\"]:\n",
    "    if level in ranges.get(\"Combined\", {}):\n",
    "        print(f\"\\n{level.upper()}:\")\n",
    "        for prop, (low, high) in ranges[\"Combined\"][level].items():\n",
    "            print(f\"  {prop}: {low:.2f} - {high:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. View Available Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import SMILEY_PROMPTS, GPT_ZINC_PROMPTS\n",
    "\n",
    "# View SmileyLlama prompts (instruction-style)\n",
    "print(\"SmileyLlama Prompts (instruction-style):\")\n",
    "smiley_df = pd.DataFrame({\"name\": [p.name for p in SMILEY_PROMPTS], \"text\": [p.text for p in SMILEY_PROMPTS]})\n",
    "smiley_df\n",
    "\n",
    "# View GPT2-Zinc prefixes (prefix-style)\n",
    "print(\"\\nGPT2-Zinc Prefixes (prefix-style):\")\n",
    "gpt_zinc_df = pd.DataFrame({\"name\": [p.name for p in GPT_ZINC_PROMPTS], \"text\": [p.text for p in GPT_ZINC_PROMPTS]})\n",
    "gpt_zinc_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GPT2-Zinc Baseline Generation (Constraint-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.baseline_generate_constraint import run_constraint_experiment\n",
    "\n",
    "# Run experiments for each constraint level\n",
    "for level in [\"loose\", \"tight\", \"ultra_tight\"]:\n",
    "    print(f\"\\nRunning {level} constraints...\")\n",
    "    run_constraint_experiment(\n",
    "        constraint_level=level,\n",
    "        property_ranges_path=\"data/train_property_ranges.json\",\n",
    "        dataset=\"Combined\",\n",
    "        n=1_000,\n",
    "        temperature=1.0,\n",
    "        top_p=0.9,\n",
    "        batch_size=256,\n",
    "        out_csv=f\"results/baseline_{level}_results.csv\",\n",
    "        summary_csv=f\"results/baseline_{level}_summary.csv\",\n",
    "    )\n",
    "\n",
    "# Combine results\n",
    "import glob\n",
    "files = sorted(glob.glob('results/baseline_*_results.csv'))\n",
    "if files:\n",
    "    dfs = [pd.read_csv(f) for f in files]\n",
    "    combined = pd.concat(dfs, ignore_index=True)\n",
    "    combined.to_csv('results/baseline_results.csv', index=False)\n",
    "    print(f\"\\nCombined {len(files)} files into baseline_results.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SmileyLlama Generation (Constraint-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.smiley_generate_constraint import run_constraint_experiment\n",
    "\n",
    "# Run experiments for each constraint level\n",
    "for level in [\"loose\", \"tight\", \"ultra_tight\"]:\n",
    "    print(f\"\\nRunning {level} constraints...\")\n",
    "    run_constraint_experiment(\n",
    "        constraint_level=level,\n",
    "        property_ranges_path=\"data/train_property_ranges.json\",\n",
    "        dataset=\"Combined\",\n",
    "        base_prompt_name=\"mw_logp_rotb\",\n",
    "        n=1_000,\n",
    "        temperature=1.0,\n",
    "        top_p=0.9,\n",
    "        batch_size=128,\n",
    "        quantize=True,\n",
    "        out_csv=f\"results/smiley_{level}_results.csv\",\n",
    "        summary_csv=f\"results/smiley_{level}_summary.csv\",\n",
    "    )\n",
    "\n",
    "# Combine results\n",
    "files = sorted(glob.glob('results/smiley_*_results.csv'))\n",
    "if files:\n",
    "    dfs = [pd.read_csv(f) for f in files]\n",
    "    combined = pd.concat(dfs, ignore_index=True)\n",
    "    combined.to_csv('results/smiley_results.csv', index=False)\n",
    "    print(f\"\\nCombined {len(files)} files into smiley_results.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import evaluate\n",
    "\n",
    "evaluate.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View summary table\n",
    "pd.read_csv(\"results/summary_table.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"results/panel_table.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import plots\n",
    "\n",
    "plots.main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
