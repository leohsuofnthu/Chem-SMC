{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two paths to controlled molecule generation â€” ChemGPT+SMC vs SmileyLlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "environment"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare ZINC data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_prep import run_data_prep\n",
    "\n",
    "run_data_prep(\n",
    "    input_path=None,  # Provide path if zinc250k not under data/\n",
    "    output_dir=\"data\",\n",
    "    ranges_path=\"data/zinc_property_ranges.json\",\n",
    "    seed=42,\n",
    "    ref_size=240_000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"data/zinc_property_ranges.json\", \"r\", encoding=\"utf-8\") as fp:\n",
    "    ranges = json.load(fp)\n",
    "\n",
    "pd.DataFrame(ranges).T.rename(columns={0: \"p05\", 1: \"p95\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prompts for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import PROMPTS\n",
    "\n",
    "prompt_names = [p.name for p in PROMPTS]\n",
    "pd.DataFrame({\"name\": [p.name for p in PROMPTS], \"prompt\": [p.text for p in PROMPTS]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline ChemGPT generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import baseline_generate\n",
    "\n",
    "baseline_generate.run_experiment(\n",
    "    prompt_names=prompt_names,\n",
    "    out_csv=\"results/baseline_results.csv\",\n",
    "    summary_csv=\"results/baseline_summary.csv\",\n",
    "    n=1_000,\n",
    "    temperatures=[1.0, 0.7],\n",
    "    top_p=0.9,\n",
    "    max_new_tokens=128,\n",
    "    batch_size=64,\n",
    "    seed=42,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ChemGPT + GenLM SMC decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import smc_generate\n",
    "\n",
    "smc_generate.run_experiment(\n",
    "    prompt_names=prompt_names,\n",
    "    out_csv=\"results/smc_results.csv\",\n",
    "    summary_csv=\"results/smc_summary.csv\",\n",
    "    n=1_000,\n",
    "    temperatures=[1.0, 0.7],\n",
    "    top_p=0.9,\n",
    "    particles=10,\n",
    "    ess_threshold=0.5,\n",
    "    max_new_tokens=128,\n",
    "    seed=43,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SmileyLlama inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import smiley_generate\n",
    "\n",
    "smiley_generate.run_experiment(\n",
    "    prompt_names=prompt_names,\n",
    "    out_csv=\"results/smiley_results.csv\",\n",
    "    summary_csv=\"results/smiley_summary.csv\",\n",
    "    n=1_000,\n",
    "    temperatures=[1.0],\n",
    "    top_p=0.9,\n",
    "    max_new_tokens=128,\n",
    "    batch_size=50,\n",
    "    seed=44,\n",
    "    device=None,\n",
    "    quantize=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import evaluate\n",
    "\n",
    "evaluate.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"results/qed_table.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"results/panel_table.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import plots\n",
    "\n",
    "plots.main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
